{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntrajic/generative-nlp-with-variational-autoencoders-3834359/blob/main/Chapter1/Exercises/Chapter1Challenge_SiameseNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge: Create a Siamese Network with Custom Layers, Custom Losses, and Custom Outputs"
      ],
      "metadata": {
        "id": "NZI62dnUfFKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Siamese Network using Keras to determine if two MNIST images are of the same digit involves several steps. A Siamese Network typically consists of two identical subnetworks with shared weights. The output is a measure of similarity between the inputs. For this task, we'll also add a custom layer and a custom loss function suitable for comparing similarity.\n",
        "\n",
        "Here are the steps we'll follow:\n",
        "\n",
        "1. Load the MNIST Dataset: We'll use the MNIST dataset available in Keras.\n",
        "\n",
        "1. Define the Custom Layer: This could be a simple layer for demonstration purposes.\n",
        "\n",
        "1. Define the Siamese Network Architecture: The architecture will consist of two identical subnetworks.\n",
        "\n",
        "1. Implement a Custom Loss Function: Suitable for a Siamese network, typically a contrastive loss function.\n",
        "\n",
        "1. Prepare the Data: Format the MNIST data for the Siamese network training.\n",
        "\n",
        "1. Compile and Train the Model: Using the custom loss function.\n",
        "\n",
        "\n",
        "Here is a nice image to represent a Siamese Network:\n",
        "\n",
        "\n",
        "![](https://pyimagesearch.com/wp-content/uploads/2020/11/keras_siamese_networks_header.png)\n",
        "\n",
        "The difference in our case is that we are not going to use a ConvNet but a normal Fully Connected network with a custom layer, and that at the end we are not going to apply the sigmoid loss so our output will be the euclidean distance between the images, a low value represents images being equal and a high value being different"
      ],
      "metadata": {
        "id": "4brRiqfDfLhu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nKA0Ms_WZEeQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Lambda, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Custom Layer (for demonstration)\n",
        "class CustomLayer(Layer):\n",
        "    def __init__(self, units=32, **kwargs):\n",
        "        super(CustomLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w)\n",
        "\n",
        "# 3. Base network to be shared (Siamese)\n",
        "def create_base_network(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "    x = Flatten()(input)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = CustomLayer(64)(x)  # Custom layer\n",
        "    return Model(input, x)\n",
        "\n",
        "# The shape of individual input images\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Create the base network\n",
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "# Create the left input and point to the base network\n",
        "input_a = Input(shape=input_shape)\n",
        "processed_a = base_network(input_a)\n",
        "\n",
        "# Create the right input and point to the base network\n",
        "input_b = Input(shape=input_shape)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "# Custom Layer or Function to compute the distance\n",
        "def euclidean_distance(vectors):\n",
        "    a, b = vectors\n",
        "    sum_square = tf.reduce_sum(tf.square(a - b), axis=1, keepdims=True)\n",
        "    return tf.sqrt(tf.maximum(sum_square, tf.keras.backend.epsilon()))\n",
        "\n",
        "distance = Lambda(euclidean_distance)([processed_a, processed_b])\n",
        "\n",
        "# Create the Siamese Network model\n",
        "model = Model([input_a, input_b], distance)"
      ],
      "metadata": {
        "id": "CaCzT3T_VXYw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Custom Contrastive Loss Function\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    square_pred = tf.square(y_pred)\n",
        "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
        "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)"
      ],
      "metadata": {
        "id": "4607QG43Vjhd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Function to create pairs\n",
        "def create_pairs(x, digit_indices):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
        "\n",
        "    for d in range(10):\n",
        "        for i in range(n):\n",
        "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
        "            pairs += [[x[z1], x[z2]]]\n",
        "            inc = random.randrange(1, 10)\n",
        "            dn = (d + inc) % 10\n",
        "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
        "            pairs += [[x[z1], x[z2]]]\n",
        "            labels += [1, 0]\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "# 5. Create digit indices\n",
        "digit_indices_train = [np.where(y_train == i)[0] for i in range(10)]\n",
        "digit_indices_test = [np.where(y_test == i)[0] for i in range(10)]\n",
        "\n",
        "# 5. Prepare the pairs\n",
        "train_pairs, train_labels = create_pairs(x_train, digit_indices_train)"
      ],
      "metadata": {
        "id": "LImHmsyMVlGA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEIejvuIVr2R",
        "outputId": "0b73c151-9a59-4483-ea34-9507de3c552e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108400,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Compile the model\n",
        "model.compile(loss=contrastive_loss, optimizer='adam')\n",
        "\n",
        "# 6. Train the model\n",
        "model.fit([train_pairs[:, 0, :,:], train_pairs[:, 1, :,:]], train_labels, batch_size=128, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYUtkxEyVxMB",
        "outputId": "2f3b1c56-aae5-4708-d8db-2469b195535a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.1408\n",
            "Epoch 2/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0693\n",
            "Epoch 3/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0577\n",
            "Epoch 4/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0524\n",
            "Epoch 5/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0489\n",
            "Epoch 6/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0459\n",
            "Epoch 7/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0442\n",
            "Epoch 8/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0418\n",
            "Epoch 9/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0405\n",
            "Epoch 10/10\n",
            "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0393\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79a364100550>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate and make predictions with the Siamese Network, we'll add steps to visualize the images being tested along with their predictions. We'll create a function to visualize pairs of images and their similarity score, and we'll also evaluate the model on a test set.\n",
        "\n",
        "Here's how we can do it:\n",
        "\n",
        "Prepare the Test Data: Create pairs from the MNIST test set and their labels.\n",
        "\n",
        "Evaluate the Model: Use the model to evaluate these pairs.\n",
        "\n",
        "Prediction and Visualization: Make predictions on a subset of these pairs and visualize the results."
      ],
      "metadata": {
        "id": "V3szwQ-3V-3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Prepare the Test Data\n",
        "test_pairs, test_labels = create_pairs(x_test, digit_indices_test)\n",
        "\n",
        "# 2. Evaluate the model\n",
        "model.evaluate([test_pairs[:, 0], test_pairs[:, 1]], test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxwdeX7lWAZR",
        "outputId": "a44bf1e7-7462-4493-aa76-14bcfeb16dc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04798704385757446"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Make predictions on a sample of test pairs\n",
        "n = 10  # Number of sample pairs to visualize\n",
        "sample_pairs = test_pairs[:n, :]\n",
        "sample_labels = test_labels[:n]\n",
        "predictions = model.predict([sample_pairs[:, 0], sample_pairs[:, 1]])\n",
        "print(f'Predictions are {predictions}')\n",
        "print(f'Labels are {sample_labels}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ockqeuzsWGfi",
        "outputId": "40746ad3-3cad-4679-9b19-c5c0dd245b12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\n",
            "Predictions are [[0.03671904]\n",
            " [0.81364566]\n",
            " [0.03901041]\n",
            " [0.78875977]\n",
            " [0.04539647]\n",
            " [0.7693171 ]\n",
            " [0.09018993]\n",
            " [1.4512309 ]\n",
            " [0.15611188]\n",
            " [1.2585396 ]]\n",
            "Labels are [1 0 1 0 1 0 1 0 1 0]\n"
          ]
        }
      ]
    }
  ]
}